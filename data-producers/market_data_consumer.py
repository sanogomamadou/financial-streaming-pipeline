import json
import time
from kafka import KafkaConsumer
from datetime import datetime, timezone  # CHANGEMENT IMPORTANT ICI
import threading
import logging
from collections import defaultdict, Counter

# Configuration du logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class MarketDataConsumer:
    def __init__(self, bootstrap_servers='localhost:9092'):
        self.bootstrap_servers = bootstrap_servers
        self.consumers = {}
        self.metrics = {
            'message_counts': Counter(),
            'last_prices': {},
            'throughput': defaultdict(list),
            'latencies': defaultdict(list)
        }
        self.running = False
        
        # Topics √† monitorer
        self.topics = [
            'stocks.AAPL', 'stocks.GOOGL', 'stocks.MSFT', 
            'stocks.TSLA', 'stocks.AMZN', 'forex.EURUSD', 
            'forex.GBPUSD', 'crypto.BTCUSD', 'market.indicators', 
            'trading.alerts'
        ]
    
    def create_consumer(self, topic, group_id_suffix=""):
        """Cr√©e un consumer Kafka pour un topic sp√©cifique"""
        return KafkaConsumer(
            topic,
            bootstrap_servers=self.bootstrap_servers,
            value_deserializer=lambda m: json.loads(m.decode('utf-8')),
            auto_offset_reset='earliest',
            enable_auto_commit=True,
            group_id=f"test_consumer_{group_id_suffix}_{topic}",
            consumer_timeout_ms=10000
        )
    
    def parse_timestamp(self, timestamp_str):
        """Parse le timestamp en g√©rant correctement les timezones"""
        try:
            # Gestion des diff√©rents formats de timestamp
            if timestamp_str.endswith('Z'):
                # Format ISO avec Z (UTC)
                return datetime.fromisoformat(timestamp_str.replace('Z', '+00:00'))
            else:
                # Autres formats
                return datetime.fromisoformat(timestamp_str)
        except Exception as e:
            logger.warning(f"Erreur parsing timestamp {timestamp_str}: {e}")
            return datetime.now(timezone.utc)  # Fallback
    
    def calculate_latency(self, message_timestamp):
        """Calcule la latence en g√©rant les timezones"""
        try:
            # Utiliser datetime.now avec timezone UTC
            current_time = datetime.now(timezone.utc)
            
            # S'assurer que les deux datetime ont une timezone
            if message_timestamp.tzinfo is None:
                message_timestamp = message_timestamp.replace(tzinfo=timezone.utc)
            
            # Calculer la diff√©rence
            latency = (current_time - message_timestamp).total_seconds() * 1000  # en ms
            return latency
        except Exception as e:
            logger.warning(f"Erreur calcul latence: {e}")
            return 0.0
    
    def consume_topic(self, topic):
        """Consomme les messages d'un topic sp√©cifique"""
        logger.info(f"D√©marrage du consumer pour le topic: {topic}")
        
        try:
            consumer = self.create_consumer(topic, "validation")
            message_count = 0
            
            for message in consumer:
                if not self.running:
                    break
                    
                message_count += 1
                self.metrics['message_counts'][topic] += 1
                
                # Calcul de la latence (si le timestamp est pr√©sent)
                if 'timestamp' in message.value:
                    message_time = self.parse_timestamp(message.value['timestamp'])
                    latency = self.calculate_latency(message_time)
                    self.metrics['latencies'][topic].append(latency)
                
                # Stocker le dernier prix pour les topics de market data
                if topic.startswith(('stocks.', 'forex.', 'crypto.')) and 'price' in message.value:
                    symbol = message.value.get('symbol', 'unknown')
                    self.metrics['last_prices'][symbol] = message.value['price']
                
                # Afficher le message (limit√© pour √©viter le spam)
                if message_count <= 3:  # Afficher seulement les 3 premiers messages
                    logger.info(f"üì® [{topic}] Message #{message_count}: {message.value}")
                elif message_count == 4:
                    logger.info(f"üì® [{topic}] ... (messages suppl√©mentaires non affich√©s)")
                
                # Mettre √† jour le throughput toutes les 10 messages
                if message_count % 10 == 0:
                    current_minute = datetime.now(timezone.utc).strftime('%H:%M')
                    self.metrics['throughput'][topic].append((current_minute, 10))
            
            consumer.close()
            logger.info(f"Consumer arr√™t√© pour {topic}. Total messages: {message_count}")
            
        except Exception as e:
            logger.error(f"Erreur lors de la consommation du topic {topic}: {e}")
    
    def start_all_consumers(self):
        """D√©marre un thread de consommation pour chaque topic"""
        self.running = True
        threads = []
        
        logger.info("üöÄ D√©marrage de tous les consumers de test...")
        
        for topic in self.topics:
            thread = threading.Thread(target=self.consume_topic, args=(topic,))
            thread.daemon = True
            threads.append(thread)
            thread.start()
            time.sleep(0.1)  # Petit d√©lai entre chaque d√©marrage
        
        return threads
    
    def print_real_time_dashboard(self):
        """Affiche un dashboard temps r√©el des m√©triques"""
        try:
            while self.running:
                print("\n" + "="*80)
                print("üìä DASHBOARD TEMPS R√âEL - KAFKA CONSUMER")
                print("="*80)
                
                # Messages par topic
                print("\nüì® MESSAGES PAR TOPIC:")
                for topic, count in self.metrics['message_counts'].most_common():
                    print(f"   {topic}: {count} messages")
                
                # Derniers prix
                if self.metrics['last_prices']:
                    print("\nüíπ DERNIERS PRIX:")
                    for symbol, price in sorted(self.metrics['last_prices'].items()):
                        if isinstance(price, (int, float)):
                            print(f"   {symbol}: {price:.4f}")
                        else:
                            print(f"   {symbol}: {price}")
                
                # Latences moyennes
                print("\n‚è±Ô∏è  LATENCES MOYENNES (ms):")
                for topic, latencies in self.metrics['latencies'].items():
                    if latencies:
                        avg_latency = sum(latencies) / len(latencies)
                        print(f"   {topic}: {avg_latency:.2f}ms")
                
                # Throughput r√©cent
                print("\nüìà THROUGHPUT (derni√®re minute):")
                for topic, throughput_data in self.metrics['throughput'].items():
                    if throughput_data:
                        recent_count = sum(count for minute, count in throughput_data[-6:])  # 60s
                        print(f"   {topic}: {recent_count} msg/min")
                
                print(f"\nüïê Derni√®re mise √† jour: {datetime.now().strftime('%H:%M:%S')}")
                print("="*80)
                
                time.sleep(10)  # Rafra√Æchissement toutes les 10 secondes
                
        except KeyboardInterrupt:
            logger.info("Dashboard arr√™t√©")
    
    def run_validation_test(self, duration=60):
        """Ex√©cute un test de validation complet"""
        logger.info(f"üß™ D√©marrage du test de validation pour {duration} secondes")
        
        # D√©marrer tous les consumers
        threads = self.start_all_consumers()
        
        # D√©marrer le dashboard
        dashboard_thread = threading.Thread(target=self.print_real_time_dashboard)
        dashboard_thread.daemon = True
        dashboard_thread.start()
        
        try:
            # Attendre la dur√©e sp√©cifi√©e
            time.sleep(duration)
            
            # Arr√™ter proprement
            self.running = False
            logger.info("Test de validation termin√©")
            
            # G√©n√©rer un rapport final
            self.generate_final_report()
            
        except KeyboardInterrupt:
            logger.info("Test interrompu par l'utilisateur")
            self.running = False
    
    def generate_final_report(self):
        """G√©n√®re un rapport d√©taill√© du test"""
        print("\n" + "="*80)
        print("üìã RAPPORT FINAL DE VALIDATION KAFKA")
        print("="*80)
        
        total_messages = sum(self.metrics['message_counts'].values())
        print(f"\nüìä TOTAL DES MESSAGES TRAIT√âS: {total_messages}")
        
        print("\nüì® D√âTAIL PAR TOPIC:")
        for topic, count in self.metrics['message_counts'].most_common():
            percentage = (count / total_messages * 100) if total_messages > 0 else 0
            print(f"   {topic}: {count} messages ({percentage:.1f}%)")
        
        print("\n‚è±Ô∏è  PERFORMANCES:")
        for topic, latencies in self.metrics['latencies'].items():
            if latencies:
                avg_latency = sum(latencies) / len(latencies)
                max_latency = max(latencies)
                min_latency = min(latencies)
                print(f"   {topic}:")
                print(f"      Moyenne: {avg_latency:.2f}ms")
                print(f"      Min: {min_latency:.2f}ms")
                print(f"      Max: {max_latency:.2f}ms")
                print(f"      √âchantillons: {len(latencies)}")
        
        # V√©rification de la sant√© des donn√©es
        print("\n‚úÖ V√âRIFICATION DE LA SANT√â DES DONN√âES:")
        healthy = True
        
        for topic in self.topics:
            if topic in self.metrics['message_counts']:
                count = self.metrics['message_counts'][topic]
                if count > 0:
                    print(f"   ‚úì {topic}: DONN√âES D√âTECT√âES ({count} messages)")
                else:
                    print(f"   ‚ö† {topic}: TOPIC VIDE (mais accessible)")
                    healthy = False
            else:
                print(f"   ‚úó {topic}: TOPIC NON ACC√âSSIBLE")
                healthy = False
        
        if healthy:
            print("\nüéâ TOUS LES TESTS SONT PASS√âS AVEC SUCC√àS!")
        else:
            print("\n‚ö†Ô∏è  CERTAINS TESTS ONT √âCHOU√â - V√âRIFIEZ LA CONFIGURATION KAFKA")

def quick_test():
    """Test rapide pour v√©rifier la connectivit√© Kafka"""
    print("üß™ TEST RAPIDE DE CONNECTIVIT√â KAFKA")
    
    try:
        # Test de connexion basique
        consumer = KafkaConsumer(
            bootstrap_servers='localhost:9092',
            group_id='quick_test',
            consumer_timeout_ms=5000
        )
        
        topics = consumer.topics()
        print(f"‚úÖ Connect√© √† Kafka - Topics disponibles: {len(topics)}")
        
        for topic in sorted(topics):
            partitions = consumer.partitions_for_topic(topic)
            print(f"   üìÅ {topic} ({len(partitions)} partitions)")
        
        consumer.close()
        
    except Exception as e:
        print(f"‚ùå Erreur de connexion Kafka: {e}")

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='Consumer de test pour donn√©es de march√© Kafka')
    parser.add_argument('--quick-test', action='store_true', help='Test rapide de connectivit√©')
    parser.add_argument('--duration', type=int, default=60, help='Dur√©e du test en secondes')
    parser.add_argument('--topic', type=str, help='Test un topic sp√©cifique seulement')
    
    args = parser.parse_args()
    
    if args.quick_test:
        quick_test()
    else:
        consumer = MarketDataConsumer()
        
        if args.topic:
            # Test d'un seul topic
            logger.info(f"Test du topic sp√©cifique: {args.topic}")
            consumer.topics = [args.topic]
            consumer.consume_topic(args.topic)
        else:
            # Test complet
            consumer.run_validation_test(duration=args.duration)